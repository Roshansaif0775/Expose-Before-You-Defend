import os
import logging
import argparse
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import models
from exposes import unlearn
from datasets.poison_tool_cifar import get_test_loader, split_dataset

# Set device (GPU if available)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Fix random seeds for reproducibility
seed = 98
torch.manual_seed(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False


def load_model_from_checkpoint(checkpoint_path, num_classes):
    """
    Load a ResNet18 model from a checkpoint file generated by backdoor_main.py.
    
    Args:
        checkpoint_path (str): Path to the checkpoint file.
        num_classes (int): Number of output classes.
    
    Returns:
        model: A PyTorch ResNet18 model instance loaded with weights from the checkpoint.
    """
    # Create a ResNet18 model
    model = models.resnet18(pretrained=False)
    model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust the final layer for the number of classes

    # Load the checkpoint
    checkpoint = torch.load(checkpoint_path, map_location=device)

    # Load the state dictionary into the model
    model.load_state_dict(checkpoint['state_dict'])

    # Move the model to the appropriate device
    model = model.to(device)

    return model


if __name__ == '__main__':
    # Logger setup
    logger = logging.getLogger(__name__)
    logging.basicConfig(
        format='[%(asctime)s] - %(message)s',
        datefmt='%Y/%m/%d %H:%M:%S',
        level=logging.DEBUG,
        handlers=[
            logging.FileHandler('/kaggle/working/output.log'),
            logging.StreamHandler()
        ])

    # Argument parser
    parser = argparse.ArgumentParser()

    # Dataset and attack parameters
    parser.add_argument('--target_label', type=int, default=0, help='class of target label')
    parser.add_argument('--trigger_type', type=str, default='gridTrigger', help='type of backdoor trigger')
    parser.add_argument('--dataset', type=str, default='CIFAR10', help='type of dataset')
    parser.add_argument('--ratio', type=float, default=0.01, help='ratio of defense data')
    parser.add_argument('--batch_size', type=int, default=128, help='batch size')
    parser.add_argument('--num_classes', type=int, default=10, help='number of classes')

    # Model paths
    parser.add_argument('--backdoor_model_path', type=str,
                        default='/kaggle/working/weights/ResNet18_gridTrigger_CIFAR10_target0_poison0.1_epoch60.tar',
                        help='path of backdoored model')
    parser.add_argument('--output_logs_path', type=str,
                        default='/kaggle/working/exposes/logs/', help='path of logger')

    args = parser.parse_args()

    # Ensure directories exist
    os.makedirs(args.output_logs_path, exist_ok=True)

    # Data loaders
    _, split_set = split_dataset(dataset_name=args.dataset, ratio=args.ratio, perm=None)
    defense_data_loader = DataLoader(split_set, batch_size=args.batch_size, shuffle=True, num_workers=4)
    clean_test_loader, bad_test_loader = get_test_loader(args)

    logger.info('----------- Data Initialization --------------')
    data_loader = {
        'defense_loader': defense_data_loader,
        'clean_test_loader': clean_test_loader,
        'bad_test_loader': bad_test_loader
    }

    logger.info('----------- Model Initialization --------------')
    # Load the backdoored model
    net = load_model_from_checkpoint(args.backdoor_model_path, num_classes=args.num_classes)
    logger.info('Backdoored model loaded successfully.')

    logger.info('----------- Model Exposing Strategy (Unlearning) --------------')
    # Perform unlearning
    unlearn_strategy = unlearn.Unlearning(args, logger, net, data_loader)
    unlearn_strategy.do_expose()
